"""
å®Œæ•´è®¤çŸ¥ç³»ç»Ÿé›†æˆæµ‹è¯•
æµ‹è¯•DPAè®¤çŸ¥ç³»ç»Ÿå„ä¸ªç»„ä»¶çš„ååŒå·¥ä½œ
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from src.cognitive import (
    DPACognitiveState,
    StateManager,
    create_cognitive_storage,
    create_memory_bank_manager,
    create_cognitive_workflow,
    create_s2_chunker,
    create_hybrid_retrieval_system,
    create_metacognitive_engine,
    hybrid_search
)
from src.utils.logger import get_logger
from langchain_core.messages import HumanMessage

logger = get_logger(__name__)


async def test_complete_cognitive_pipeline():
    """æµ‹è¯•å®Œæ•´çš„è®¤çŸ¥å¤„ç†æµæ°´çº¿"""
    logger.info("=== æµ‹è¯•å®Œæ•´è®¤çŸ¥å¤„ç†æµæ°´çº¿ ===")
    
    # 1. åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ï¼ˆä½¿ç”¨çœŸå®APIï¼‰
    config = {"mock_mode": False}
    
    storage = create_cognitive_storage()
    memory_bank = create_memory_bank_manager()
    workflow = create_cognitive_workflow(config)
    s2_chunker = create_s2_chunker(config)
    retrieval_system = create_hybrid_retrieval_system(config)
    metacognitive_engine = create_metacognitive_engine(config)
    
    logger.info("æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    # 2. åˆ›å»ºåˆå§‹è®¤çŸ¥çŠ¶æ€
    state_manager = StateManager()
    cognitive_state = state_manager.create_initial_state("test_user", "test_project")
    
    # 3. æ¨¡æ‹Ÿæ–‡æ¡£å¤„ç†æµç¨‹
    test_document = """
    è®¤çŸ¥æ¶æ„æ˜¯å¿ƒç†å­¦å’Œè®¤çŸ¥ç§‘å­¦ä¸­çš„ä¸€ä¸ªé‡è¦æ¦‚å¿µï¼Œå®ƒæè¿°äº†äººç±»å¿ƒæ™ºçš„åŸºæœ¬ç»“æ„å’Œæ“ä½œåŸç†ã€‚
    è®¤çŸ¥æ¶æ„è¯•å›¾è§£é‡Šäººç±»å¦‚ä½•æ„ŸçŸ¥ã€å­¦ä¹ ã€è®°å¿†ã€æ¨ç†å’Œè§£å†³é—®é¢˜ã€‚ä¸»è¦çš„è®¤çŸ¥æ¶æ„ç†è®ºåŒ…æ‹¬ï¼š
    
    1. ACT-R (Adaptive Control of Thought-Rational) - ç”±çº¦ç¿°Â·å®‰å¾·æ£®å¼€å‘çš„è®¤çŸ¥æ¶æ„
    2. SOAR (State, Operator, and Result) - è‰¾ä¼¦Â·çº½ç»´å°”ç­‰äººå¼€å‘çš„é—®é¢˜è§£å†³æ¶æ„  
    3. CLARION - åˆ†å±‚è®¤çŸ¥æ¶æ„ï¼ŒåŒºåˆ†æ˜¾å¼å’Œéšå¼å¤„ç†
    
    è¿™äº›æ¶æ„éƒ½è¯•å›¾å»ºæ¨¡äººç±»è®¤çŸ¥çš„ä¸åŒæ–¹é¢ï¼ŒåŒ…æ‹¬å·¥ä½œè®°å¿†ã€é•¿æœŸè®°å¿†ã€æ³¨æ„åŠ›å’Œå­¦ä¹ æœºåˆ¶ã€‚
    """
    
    logger.info("å¼€å§‹æ–‡æ¡£åˆ†å—å¤„ç†...")
    
    # 4. S2è¯­ä¹‰åˆ†å—
    chunks = await s2_chunker.chunk_document(test_document, {"source": "cognitive_theory"})
    logger.info(f"æ–‡æ¡£åˆ†å—å®Œæˆï¼Œè·å¾— {len(chunks)} ä¸ªåˆ†å—")
    
    # 5. å‘è®¤çŸ¥çŠ¶æ€æ·»åŠ åˆ†å—ç»“æœ
    cognitive_state["s2_chunks"] = [chunk.__dict__ for chunk in chunks]
    
    # 6. æ‰§è¡Œæ··åˆæ£€ç´¢
    logger.info("æµ‹è¯•æ··åˆæ£€ç´¢...")
    retrieval_response = await hybrid_search(
        "ä»€ä¹ˆæ˜¯è®¤çŸ¥æ¶æ„çš„ä¸»è¦ç‰¹ç‚¹ï¼Ÿ",
        query_type="semantic",
        max_results=10
    )
    logger.info(f"æ£€ç´¢å®Œæˆï¼Œè·å¾— {len(retrieval_response['results'])} ä¸ªç»“æœ")
    
    # 7. æ·»åŠ ç”¨æˆ·æŸ¥è¯¢åˆ°è®¤çŸ¥çŠ¶æ€
    cognitive_state["messages"].append(
        HumanMessage(content="è¯·è§£é‡Šè®¤çŸ¥æ¶æ„çš„åŸºæœ¬æ¦‚å¿µå’Œä¸»è¦ç±»å‹")
    )
    
    # 8. æ‰§è¡Œå…ƒè®¤çŸ¥å¾ªç¯
    logger.info("æ‰§è¡Œå…ƒè®¤çŸ¥è¯„ä¼°...")
    task_context = {
        "task_type": "explanation",
        "query": "è¯·è§£é‡Šè®¤çŸ¥æ¶æ„çš„åŸºæœ¬æ¦‚å¿µå’Œä¸»è¦ç±»å‹",
        "task_complexity": 0.7,
        "accuracy_requirement": 0.8,
        "start_time": datetime.now(),
        "task_completed": True
    }
    
    metacognitive_report = await metacognitive_engine.metacognitive_cycle(
        cognitive_state, task_context
    )
    
    logger.info(f"å…ƒè®¤çŸ¥è¯„ä¼°å®Œæˆ:")
    logger.info(f"  å½“å‰ç­–ç•¥: {metacognitive_report['metacognitive_state']['current_strategy']}")
    logger.info(f"  ç½®ä¿¡æ°´å¹³: {metacognitive_report['metacognitive_state']['confidence_level']}")
    logger.info(f"  æ€§èƒ½è¯„åˆ†: {metacognitive_report['performance']['overall_score']:.3f}")
    
    # 9. ä¿å­˜è®¤çŸ¥çŠ¶æ€
    await storage.save_cognitive_state(cognitive_state)
    logger.info("è®¤çŸ¥çŠ¶æ€å·²ä¿å­˜")
    
    # 10. ç”Ÿæˆå¤„ç†æŠ¥å‘Š
    processing_report = {
        "timestamp": datetime.now().isoformat(),
        "document_length": len(test_document),
        "chunks_created": len(chunks),
        "retrieval_results": len(retrieval_response['results']),
        "metacognitive_strategy": metacognitive_report['metacognitive_state']['current_strategy'],
        "performance_score": metacognitive_report['performance']['overall_score'],
        "confidence_level": metacognitive_report['metacognitive_state']['confidence_level'],
        "working_memory_usage": len(cognitive_state["working_memory"]) / 7,
        "episodic_memory_count": len(cognitive_state["episodic_memory"]),
        "semantic_memory_count": len(cognitive_state["semantic_memory"])
    }
    
    logger.info(f"å¤„ç†æŠ¥å‘Š:")
    for key, value in processing_report.items():
        logger.info(f"  {key}: {value}")
    
    return processing_report


async def test_cognitive_workflow_integration():
    """æµ‹è¯•è®¤çŸ¥å·¥ä½œæµé›†æˆ"""
    logger.info("\n=== æµ‹è¯•è®¤çŸ¥å·¥ä½œæµé›†æˆ ===")
    
    # åˆ›å»ºå·¥ä½œæµï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
    workflow = create_cognitive_workflow({"mock_mode": True})
    
    # åˆ›å»ºåˆå§‹çŠ¶æ€
    state_manager = StateManager()
    initial_state = state_manager.create_initial_state("test_user", "integration_test")
    
    # æ·»åŠ æµ‹è¯•æ¶ˆæ¯
    initial_state["messages"] = [
        HumanMessage(content="åˆ†æè®¤çŸ¥è´Ÿè·ç†è®ºåœ¨æ•™è‚²ä¸­çš„åº”ç”¨")
    ]
    
    # æµ‹è¯•æ„ŸçŸ¥èŠ‚ç‚¹
    logger.info("æµ‹è¯•æ„ŸçŸ¥èŠ‚ç‚¹...")
    state_after_perceive = await workflow.perceive_input(initial_state)
    logger.info(f"æ„ŸçŸ¥å®Œæˆï¼Œæ„Ÿè§‰ç¼“å†²é¡¹æ•°: {len(state_after_perceive['sensory_buffer'])}")
    
    # æµ‹è¯•æ³¨æ„åŠ›èŠ‚ç‚¹
    logger.info("æµ‹è¯•æ³¨æ„åŠ›èŠ‚ç‚¹...")
    state_after_attend = await workflow.focus_attention(state_after_perceive)
    logger.info(f"æ³¨æ„åŠ›èšç„¦å®Œæˆï¼Œå·¥ä½œè®°å¿†é¡¹æ•°: {len(state_after_attend['working_memory'])}")
    
    # æµ‹è¯•è®°å¿†ç¼–ç èŠ‚ç‚¹
    logger.info("æµ‹è¯•è®°å¿†ç¼–ç ...")
    state_after_encode = await workflow.encode_to_memory(state_after_attend)
    logger.info(f"è®°å¿†ç¼–ç å®Œæˆï¼Œæƒ…èŠ‚è®°å¿†é¡¹æ•°: {len(state_after_encode['episodic_memory'])}")
    
    # æµ‹è¯•æ¨ç†èŠ‚ç‚¹
    logger.info("æµ‹è¯•æ¨ç†å¼•æ“...")
    state_after_reason = await workflow.reasoning_engine(state_after_encode)
    logger.info(f"æ¨ç†å®Œæˆï¼Œæ¶ˆæ¯æ•°: {len(state_after_reason['messages'])}")
    
    return state_after_reason


async def test_memory_system_integration():
    """æµ‹è¯•è®°å¿†ç³»ç»Ÿé›†æˆ"""
    logger.info("\n=== æµ‹è¯•è®°å¿†ç³»ç»Ÿé›†æˆ ===")
    
    # åˆ›å»ºè®°å¿†åº“ç®¡ç†å™¨
    memory_bank = create_memory_bank_manager()
    
    # è¯»å–è®°å¿†
    memories = await memory_bank.read_all_memories()
    logger.info(f"è¯»å–è®°å¿†å®Œæˆï¼ŒåŒ…å« {len(memories)} ä¸ªè®°å¿†ç±»å‹")
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€ç”¨äºæ›´æ–°è®°å¿†
    test_state = {
        "project_id": "integration_test",
        "new_insights": [
            {"content": "è®¤çŸ¥æ¶æ„æ•´åˆæ´å¯Ÿ", "confidence": 0.9, "timestamp": datetime.now().isoformat()},
            {"content": "å…ƒè®¤çŸ¥ç­–ç•¥ä¼˜åŒ–", "confidence": 0.8, "timestamp": datetime.now().isoformat()}
        ],
        "concept_embeddings": {"integration": [0.1] * 10},
        "learning_hypotheses": [{"id": "hyp1", "content": "é›†æˆæµ‹è¯•å‡è®¾"}],
        "knowledge_gaps": [{"description": "é›†æˆè¿‡ç¨‹ä¸­çš„çŸ¥è¯†ç›²ç‚¹"}]
    }
    
    # æ›´æ–°åŠ¨æ€æ‘˜è¦
    await memory_bank.update_dynamic_summary(test_state)
    logger.info("è®°å¿†åº“æ›´æ–°å®Œæˆ")
    
    # éªŒè¯æ›´æ–°
    updated_memories = await memory_bank.read_all_memories()
    logger.info(f"æ›´æ–°åè®°å¿†éªŒè¯: {len(updated_memories)} ä¸ªè®°å¿†ç±»å‹")
    
    return updated_memories


async def test_retrieval_metacognition_loop():
    """æµ‹è¯•æ£€ç´¢-å…ƒè®¤çŸ¥åé¦ˆå¾ªç¯"""
    logger.info("\n=== æµ‹è¯•æ£€ç´¢-å…ƒè®¤çŸ¥åé¦ˆå¾ªç¯ ===")
    
    # åˆå§‹åŒ–ç»„ä»¶
    retrieval_system = create_hybrid_retrieval_system({"mock_mode": True})
    metacognitive_engine = create_metacognitive_engine({"mock_mode": True})
    
    # åˆ›å»ºè®¤çŸ¥çŠ¶æ€
    state_manager = StateManager()
    cognitive_state = state_manager.create_initial_state("test_user", "feedback_test")
    
    # æ¨¡æ‹Ÿå¤šè½®æ£€ç´¢-è¯„ä¼°å¾ªç¯
    queries = [
        "è®¤çŸ¥æ¶æ„çš„åŸºæœ¬åŸç†",
        "å·¥ä½œè®°å¿†çš„å®¹é‡é™åˆ¶",
        "å…ƒè®¤çŸ¥ç­–ç•¥çš„åº”ç”¨"
    ]
    
    for i, query in enumerate(queries):
        logger.info(f"ç¬¬ {i+1} è½®: {query}")
        
        # æ‰§è¡Œæ£€ç´¢
        retrieval_response = await hybrid_search(query, max_results=5)
        
        # æ›´æ–°è®¤çŸ¥çŠ¶æ€
        cognitive_state["messages"].append(HumanMessage(content=query))
        
        # å…ƒè®¤çŸ¥è¯„ä¼°
        task_context = {
            "task_type": "retrieval",
            "query": query,
            "task_complexity": 0.5 + i * 0.1,
            "start_time": datetime.now(),
            "task_completed": True
        }
        
        metacognitive_report = await metacognitive_engine.metacognitive_cycle(
            cognitive_state, task_context
        )
        
        logger.info(f"  æ£€ç´¢ç»“æœ: {len(retrieval_response['results'])} é¡¹")
        logger.info(f"  ç­–ç•¥: {metacognitive_report['strategy']['current']}")
        logger.info(f"  æ€§èƒ½: {metacognitive_report['performance']['overall_score']:.3f}")
        
        # æ¨¡æ‹Ÿç­–ç•¥è°ƒæ•´å½±å“ä¸‹ä¸€è½®æ£€ç´¢
        if metacognitive_report['strategy']['changed']:
            logger.info(f"  ç­–ç•¥å·²è°ƒæ•´ä¸º: {metacognitive_report['strategy']['current']}")
    
    # è·å–å…ƒè®¤çŸ¥æ´å¯Ÿ
    insights = metacognitive_engine.get_metacognitive_insights()
    logger.info(f"è·å¾— {len(insights['insights'])} ä¸ªæ´å¯Ÿ")
    
    return insights


async def test_system_performance():
    """æµ‹è¯•ç³»ç»Ÿæ€§èƒ½"""
    logger.info("\n=== æµ‹è¯•ç³»ç»Ÿæ€§èƒ½ ===")
    
    start_time = datetime.now()
    
    # å¹¶è¡Œåˆå§‹åŒ–å¤šä¸ªç»„ä»¶
    tasks = [
        create_cognitive_storage(),
        create_memory_bank_manager(),
        create_s2_chunker({"mock_mode": True}),
        create_hybrid_retrieval_system({"mock_mode": True}),
        create_metacognitive_engine({"mock_mode": True})
    ]
    
    # ç­‰å¾…æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ - ç®€åŒ–ä¸ºç›´æ¥ä½¿ç”¨
    components = tasks  # è¿™äº›å·²ç»æ˜¯åˆå§‹åŒ–å¥½çš„ç»„ä»¶
    
    initialization_time = (datetime.now() - start_time).total_seconds()
    logger.info(f"ç»„ä»¶åˆå§‹åŒ–æ—¶é—´: {initialization_time:.3f}ç§’")
    
    # æµ‹è¯•å¹¶å‘å¤„ç†
    start_time = datetime.now()
    
    concurrent_tasks = []
    for i in range(5):
        task = hybrid_search(
            f"æµ‹è¯•æŸ¥è¯¢ {i}",
            query_type="semantic",
            max_results=5
        )
        concurrent_tasks.append(task)
    
    # å¹¶å‘æ‰§è¡Œæ£€ç´¢
    results = await asyncio.gather(*concurrent_tasks)
    
    concurrent_time = (datetime.now() - start_time).total_seconds()
    logger.info(f"å¹¶å‘æ£€ç´¢æ—¶é—´: {concurrent_time:.3f}ç§’")
    logger.info(f"å¹³å‡æ¯æ¬¡æ£€ç´¢: {concurrent_time/5:.3f}ç§’")
    
    performance_metrics = {
        "initialization_time": initialization_time,
        "concurrent_retrieval_time": concurrent_time,
        "average_retrieval_time": concurrent_time / 5,
        "successful_retrievals": len([r for r in results if r['total_results'] > 0])
    }
    
    return performance_metrics


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹å®Œæ•´è®¤çŸ¥ç³»ç»Ÿé›†æˆæµ‹è¯•")
    
    try:
        # 1. æµ‹è¯•å®Œæ•´è®¤çŸ¥å¤„ç†æµæ°´çº¿
        processing_report = await test_complete_cognitive_pipeline()
        
        # 2. æµ‹è¯•è®¤çŸ¥å·¥ä½œæµé›†æˆ
        workflow_state = await test_cognitive_workflow_integration()
        
        # 3. æµ‹è¯•è®°å¿†ç³»ç»Ÿé›†æˆ
        memory_update = await test_memory_system_integration()
        
        # 4. æµ‹è¯•æ£€ç´¢-å…ƒè®¤çŸ¥åé¦ˆå¾ªç¯
        feedback_insights = await test_retrieval_metacognition_loop()
        
        # 5. æµ‹è¯•ç³»ç»Ÿæ€§èƒ½
        performance_metrics = await test_system_performance()
        
        logger.info("\n=== é›†æˆæµ‹è¯•æ€»ç»“ ===")
        logger.info("âœ… å®Œæ•´è®¤çŸ¥å¤„ç†æµæ°´çº¿ï¼šé€šè¿‡")
        logger.info("âœ… è®¤çŸ¥å·¥ä½œæµé›†æˆï¼šé€šè¿‡")
        logger.info("âœ… è®°å¿†ç³»ç»Ÿé›†æˆï¼šé€šè¿‡")
        logger.info("âœ… æ£€ç´¢-å…ƒè®¤çŸ¥åé¦ˆå¾ªç¯ï¼šé€šè¿‡")
        logger.info("âœ… ç³»ç»Ÿæ€§èƒ½æµ‹è¯•ï¼šé€šè¿‡")
        
        logger.info(f"\næ€§èƒ½æŒ‡æ ‡:")
        logger.info(f"  åˆå§‹åŒ–æ—¶é—´: {performance_metrics['initialization_time']:.3f}ç§’")
        logger.info(f"  å¹³å‡æ£€ç´¢æ—¶é—´: {performance_metrics['average_retrieval_time']:.3f}ç§’")
        logger.info(f"  æˆåŠŸæ£€ç´¢ç‡: {performance_metrics['successful_retrievals']}/5")
        
        logger.info(f"\nè®¤çŸ¥çŠ¶æ€:")
        logger.info(f"  æ–‡æ¡£åˆ†å—æ•°: {processing_report['chunks_created']}")
        logger.info(f"  æ£€ç´¢ç»“æœæ•°: {processing_report['retrieval_results']}")
        logger.info(f"  å½“å‰ç­–ç•¥: {processing_report['metacognitive_strategy']}")
        logger.info(f"  æ€§èƒ½è¯„åˆ†: {processing_report['performance_score']:.3f}")
        logger.info(f"  å·¥ä½œè®°å¿†ä½¿ç”¨: {processing_report['working_memory_usage']:.2f}")
        
        logger.info("\nğŸ‰ DPAè®¤çŸ¥ç³»ç»Ÿé›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        logger.info("ç³»ç»Ÿå·²å‡†å¤‡å¥½å¤„ç†å¤æ‚çš„è®¤çŸ¥ä»»åŠ¡ã€‚")
        
    except Exception as e:
        logger.error(f"é›†æˆæµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    asyncio.run(main())