#!/usr/bin/env python3
"""
æµ‹è¯•é‡æ’åºæœåŠ¡
"""

import asyncio
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.services.reranker import RerankerService
from src.utils.logger import get_logger
from datetime import datetime, timedelta

logger = get_logger(__name__)


async def test_reranker():
    """æµ‹è¯•é‡æ’åºæœåŠ¡"""
    logger.info("å¼€å§‹æµ‹è¯•é‡æ’åºæœåŠ¡...")
    
    reranker = RerankerService()
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    query = "æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨"
    
    chunks = [
        {
            "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒé€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨ç¤ºã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œæ·±åº¦å­¦ä¹ å·²ç»å–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚",
            "score": 0.85,
            "metadata": {"created_at": datetime.now() - timedelta(days=10)}
        },
        {
            "content": "ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†æ–‡æœ¬æ•°æ®æ—¶å­˜åœ¨å±€é™æ€§ã€‚æ”¯æŒå‘é‡æœºå’Œå†³ç­–æ ‘ç­‰ç®—æ³•éœ€è¦æ‰‹å·¥è®¾è®¡ç‰¹å¾ã€‚",
            "score": 0.65,
            "metadata": {"created_at": datetime.now() - timedelta(days=30)}
        },
        {
            "content": "è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹å¦‚BERTã€GPTç­‰åœ¨NLPä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€æœºå™¨ç¿»è¯‘ç­‰ã€‚",
            "score": 0.92,
            "metadata": {"created_at": datetime.now() - timedelta(days=5)}
        },
        {
            "content": "æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸä¹Ÿæœ‰å¹¿æ³›åº”ç”¨ï¼Œå¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ç­‰ã€‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ˜¯å¤„ç†å›¾åƒæ•°æ®çš„ä¸»è¦æ¶æ„ã€‚",
            "score": 0.70,
            "metadata": {"created_at": datetime.now() - timedelta(days=15)}
        },
        {
            "content": "Transformeræ¶æ„å½»åº•æ”¹å˜äº†NLPé¢†åŸŸã€‚é€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ŒTransformerèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚BERTå’ŒGPTéƒ½åŸºäºTransformeræ¶æ„ã€‚",
            "score": 0.88,
            "metadata": {"created_at": datetime.now() - timedelta(days=3)}
        },
        {
            "content": "æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨NLPä¸­çš„åº”ç”¨åŒ…æ‹¬ï¼šæƒ…æ„Ÿåˆ†æã€æ–‡æœ¬æ‘˜è¦ã€é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿç­‰ã€‚è¿™äº›åº”ç”¨å·²ç»åœ¨å®é™…äº§å“ä¸­å¾—åˆ°å¹¿æ³›éƒ¨ç½²ã€‚",
            "score": 0.90,
            "metadata": {"created_at": datetime.now() - timedelta(days=7)}
        },
        {
            "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œã€‚åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œæ·±åº¦å­¦ä¹ æŠ€æœ¯å·²ç»æˆä¸ºä¸»æµæ–¹æ³•ã€‚",  # ä¸ç¬¬ä¸€ä¸ªç›¸ä¼¼
            "score": 0.83,
            "metadata": {"created_at": datetime.now() - timedelta(days=20)}
        }
    ]
    
    # æµ‹è¯•1: ç›¸ä¼¼åº¦é‡æ’åº
    logger.info("\næµ‹è¯•1: ç›¸ä¼¼åº¦é‡æ’åº")
    similarity_result = await reranker.rerank(
        query=query,
        chunks=chunks,
        strategy="similarity",
        top_k=5
    )
    
    logger.info("ç›¸ä¼¼åº¦é‡æ’åºç»“æœ:")
    for i, chunk in enumerate(similarity_result):
        logger.info(f"{i+1}. åˆ†æ•°: {chunk['score']:.2f} - {chunk['content'][:50]}...")
    
    # æµ‹è¯•2: æ··åˆé‡æ’åº
    logger.info("\næµ‹è¯•2: æ··åˆé‡æ’åº")
    hybrid_result = await reranker.rerank(
        query=query,
        chunks=chunks,
        strategy="hybrid",
        top_k=5
    )
    
    logger.info("æ··åˆé‡æ’åºç»“æœ:")
    for i, chunk in enumerate(hybrid_result):
        score = chunk.get('hybrid_score', chunk.get('score', 0))
        logger.info(f"{i+1}. ç»¼åˆåˆ†æ•°: {score:.2f} - {chunk['content'][:50]}...")
    
    # æµ‹è¯•3: ç›¸å…³æ€§é‡æ’åºï¼ˆä½¿ç”¨LLMï¼‰
    logger.info("\næµ‹è¯•3: ç›¸å…³æ€§é‡æ’åº")
    relevance_result = await reranker.rerank(
        query=query,
        chunks=chunks[:3],  # åªç”¨å‰3ä¸ªä»¥èŠ‚çœAPIè°ƒç”¨
        strategy="relevance",
        top_k=3
    )
    
    logger.info("ç›¸å…³æ€§é‡æ’åºç»“æœ:")
    for i, chunk in enumerate(relevance_result):
        score = chunk.get('relevance_score', chunk.get('score', 0))
        logger.info(f"{i+1}. ç›¸å…³æ€§åˆ†æ•°: {score:.2f} - {chunk['content'][:50]}...")
    
    # æµ‹è¯•å»é‡åŠŸèƒ½
    logger.info("\næµ‹è¯•å»é‡åŠŸèƒ½:")
    logger.info(f"åŸå§‹å—æ•°: {len(chunks)}")
    logger.info(f"æ··åˆé‡æ’åºåå—æ•°: {len(hybrid_result)}")
    
    # éªŒè¯æ˜¯å¦å»é™¤äº†ç›¸ä¼¼å†…å®¹
    contents = [chunk['content'][:50] for chunk in hybrid_result]
    logger.info(f"å»é‡æ•ˆæœ: {'æˆåŠŸ' if len(contents) == len(set(contents)) else 'æœ‰é‡å¤'}")
    
    return True


async def test_keyword_matching():
    """æµ‹è¯•å…³é”®è¯åŒ¹é…åŠŸèƒ½"""
    logger.info("\næµ‹è¯•å…³é”®è¯åŒ¹é…åŠŸèƒ½...")
    
    reranker = RerankerService()
    
    # æµ‹è¯•å…³é”®è¯åŒ¹é…åˆ†æ•°è®¡ç®—
    test_cases = [
        {
            "query": "æ·±åº¦å­¦ä¹  è‡ªç„¶è¯­è¨€å¤„ç†",
            "content": "æ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨éå¸¸å¹¿æ³›",
            "expected": "é«˜åˆ†"
        },
        {
            "query": "æ·±åº¦å­¦ä¹  è‡ªç„¶è¯­è¨€å¤„ç†",
            "content": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯",
            "expected": "ä½åˆ†"
        },
        {
            "query": "BERT transformer",
            "content": "BERTæ˜¯åŸºäºTransformeræ¶æ„çš„é¢„è®­ç»ƒæ¨¡å‹",
            "expected": "é«˜åˆ†"
        }
    ]
    
    for case in test_cases:
        score = reranker._calculate_keyword_score(case["query"], case["content"])
        logger.info(f"æŸ¥è¯¢: {case['query']}")
        logger.info(f"å†…å®¹: {case['content']}")
        logger.info(f"å…³é”®è¯åŒ¹é…åˆ†æ•°: {score:.2f} (é¢„æœŸ: {case['expected']})")
        logger.info("")


async def test_freshness_score():
    """æµ‹è¯•æ–°é²œåº¦è¯„åˆ†"""
    logger.info("\næµ‹è¯•æ–°é²œåº¦è¯„åˆ†...")
    
    reranker = RerankerService()
    
    # æµ‹è¯•ä¸åŒæ—¶é—´çš„æ–°é²œåº¦åˆ†æ•°
    test_dates = [
        (datetime.now() - timedelta(days=1), "1å¤©å‰"),
        (datetime.now() - timedelta(days=15), "15å¤©å‰"),
        (datetime.now() - timedelta(days=60), "60å¤©å‰"),
        (datetime.now() - timedelta(days=200), "200å¤©å‰"),
        (datetime.now() - timedelta(days=400), "400å¤©å‰"),
    ]
    
    for date, desc in test_dates:
        metadata = {"created_at": date.isoformat()}
        score = reranker._calculate_freshness_score(metadata)
        logger.info(f"{desc}: æ–°é²œåº¦åˆ†æ•° = {score:.1f}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        await test_reranker()
        await test_keyword_matching()
        await test_freshness_score()
        
        logger.info("\nğŸ‰ æ‰€æœ‰é‡æ’åºæµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)