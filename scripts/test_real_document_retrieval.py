#!/usr/bin/env python3
"""
ä½¿ç”¨çœŸå®é•¿æ–‡æ¡£æµ‹è¯•æ£€ç´¢ä¼˜åŒ–æ•ˆæœ
"""
import asyncio
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))

from src.core.document.mvp_document_processor import create_mvp_document_processor
from src.core.retrieval.mvp_hybrid_retriever import create_mvp_hybrid_retriever
from src.utils.logging_utils import get_logger

logger = get_logger(__name__)


async def main():
    print("\n" + "="*80)
    print("ğŸ” çœŸå®æ–‡æ¡£æ£€ç´¢æµ‹è¯• - Memory Systems for AI Agents")
    print("="*80)
    
    # 1. å¤„ç†çœŸå®æ–‡æ¡£
    print("\nğŸ“„ å¤„ç†æ–‡æ¡£...")
    processor = create_mvp_document_processor()
    
    # ä½¿ç”¨Memory Systemsæ–‡æ¡£
    doc_path = "/Users/mdwong001/Desktop/code/rag/data/zonghe/MemeoryOpenai.txt"
    
    # å¤„ç†æ–‡æ¡£
    result = await processor.process_document(
        file_path=doc_path,
        project_id="memory_systems_demo"
    )
    
    print(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ:")
    print(f"   - æ–‡æ¡£ID: {result.document_id}")
    print(f"   - åˆ†å—æ•°é‡: {result.chunk_count}")
    print(f"   - åˆ†å—ç­–ç•¥: 150å­—ç¬¦/å—ï¼Œ30å­—ç¬¦é‡å ")
    
    # ç­‰å¾…å­˜å‚¨å®Œæˆ
    await asyncio.sleep(3)
    
    # 2. æµ‹è¯•å„ç§æŸ¥è¯¢
    print("\nğŸ” æµ‹è¯•æ£€ç´¢æ•ˆæœ...")
    retriever = create_mvp_hybrid_retriever()
    
    test_queries = [
        # æ¦‚å¿µæ€§æŸ¥è¯¢
        ("What is episodic memory?", "æƒ…æ™¯è®°å¿†æŸ¥è¯¢"),
        ("semantic memory", "è¯­ä¹‰è®°å¿†æŸ¥è¯¢"),
        ("working memory vs long-term memory", "å·¥ä½œè®°å¿†vsé•¿æœŸè®°å¿†"),
        
        # æŠ€æœ¯æ€§æŸ¥è¯¢
        ("RAG implementation", "RAGå®ç°"),
        ("fine-tuning for memory", "å¾®è°ƒè®°å¿†"),
        ("vector stores", "å‘é‡å­˜å‚¨"),
        ("catastrophic forgetting", "ç¾éš¾æ€§é—å¿˜"),
        
        # åº”ç”¨æ€§æŸ¥è¯¢
        ("personal assistant memory", "ä¸ªäººåŠ©æ‰‹è®°å¿†"),
        ("continual learning", "æŒç»­å­¦ä¹ "),
        ("memory types in AI", "AIä¸­çš„è®°å¿†ç±»å‹")
    ]
    
    success_count = 0
    for query, desc in test_queries:
        print(f"\næŸ¥è¯¢: {query} ({desc})")
        result = await retriever.retrieve(
            query=query,
            project_id="memory_systems_demo",
            top_k=3
        )
        
        print(f"âœ… æ£€ç´¢ç»“æœ:")
        print(f"   - å‘é‡æœç´¢: {len(result.vector_results)} ç»“æœ")
        
        if result.fused_results:
            success_count += 1
            print("   Topç»“æœ:")
            for i, res in enumerate(result.fused_results[:2]):
                print(f"   {i+1}. [åˆ†æ•°:{res.score:.3f}]")
                # æ¸…ç†å†…å®¹ä¸­çš„æ¢è¡Œç¬¦
                content = res.content.replace('\n', ' ').strip()
                print(f"      {content[:100]}...")
        else:
            print("   âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
    
    # 3. ç»Ÿè®¡åˆ†æ
    print("\n" + "="*80)
    print("ğŸ“Š æ£€ç´¢æ•ˆæœåˆ†æ")
    print("="*80)
    print(f"âœ… æ£€ç´¢æˆåŠŸç‡: {success_count}/{len(test_queries)} ({success_count/len(test_queries)*100:.1f}%)")
    print("\nä¼˜åŒ–æ•ˆæœ:")
    print("1. åˆ†å—ç­–ç•¥: 150å­—ç¬¦åˆ†å—ç¡®ä¿ç»†ç²’åº¦åŒ¹é…")
    print("2. ç›¸ä¼¼åº¦é˜ˆå€¼: 0.3æé«˜å¬å›ç‡")
    print("3. çœŸå®æ–‡æ¡£: ä¸“ä¸šå†…å®¹çš„è¯­ä¹‰æ£€ç´¢æµ‹è¯•")
    
    # 4. å±•ç¤ºåˆ†å—æ•ˆæœ
    print("\nğŸ“„ åˆ†å—ç¤ºä¾‹ï¼ˆå‰3ä¸ªå—ï¼‰:")
    # ä»Qdrantè·å–ä¸€äº›åˆ†å—
    from src.database.qdrant_client import get_qdrant_client
    qdrant = get_qdrant_client()
    
    try:
        # è·å–é›†åˆä¸­çš„å‰å‡ ä¸ªç‚¹
        points = await qdrant.scroll_points(
            collection_name=f"project_memory_systems_demo",
            limit=3,
            with_payload=True,
            with_vectors=False
        )
        
        for i, point in enumerate(points[0][:3]):
            print(f"\nå— {i+1}:")
            content = point.payload.get('content', '').replace('\n', ' ').strip()
            print(f"  å†…å®¹: {content[:150]}...")
            print(f"  é•¿åº¦: {len(content)} å­—ç¬¦")
    except Exception as e:
        print(f"æ— æ³•è·å–åˆ†å—ç¤ºä¾‹: {e}")


if __name__ == "__main__":
    asyncio.run(main())