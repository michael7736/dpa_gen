# æ–‡æ¡£åˆ†å—ä¼˜åŒ–æ€»ç»“

## ä¼˜åŒ–èƒŒæ™¯
åœ¨åˆå§‹æµ‹è¯•ä¸­å‘ç°ï¼Œä½¿ç”¨150å­—ç¬¦çš„åˆ†å—ç­–ç•¥å¯¼è‡´ï¼š
- 82%çš„åˆ†å—åœ¨è¯ä¸­é—´æ–­å¼€
- å¹³å‡åˆ†å—å¤§å°ä»…106å­—ç¬¦ï¼ˆç›®æ ‡150ï¼‰
- æ£€ç´¢è¦†ç›–ç‡ä½

## ç¬¬ä¸€æ­¥ä¼˜åŒ–ï¼šToken-basedåˆ†å—
**æ ¸å¿ƒæ´å¯Ÿ**ï¼š"ä¸åº”å†ä¿¡ä»»len()ã€‚å¯¹äºLLMï¼ŒçœŸæ­£çš„'é•¿åº¦'æ˜¯tokenæ•°é‡ï¼Œè€Œä¸æ˜¯å­—ç¬¦æ•°ã€‚"

### å®æ–½å†…å®¹
1. å¼•å…¥tiktokenåº“è¿›è¡Œç²¾ç¡®çš„tokenè®¡æ•°
2. å°†åˆ†å—å¤§å°ä»150å­—ç¬¦æ”¹ä¸º512 tokens
3. å°†é‡å ä»30å­—ç¬¦æ”¹ä¸º128 tokensï¼ˆ25%ï¼‰
4. ä¼˜åŒ–åˆ†éš”ç¬¦é¡ºåºï¼Œä¼˜å…ˆä¿æŒè¯­ä¹‰è¾¹ç•Œ

### ä»£ç æ”¹åŠ¨
```python
# æ·»åŠ tiktoken
import tiktoken
tokenizer = tiktoken.get_encoding("cl100k_base")

def tiktoken_len(text: str) -> int:
    tokens = tokenizer.encode(text)
    return len(tokens)

# æ›´æ–°åˆ†å—å™¨
self.text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,  # tokens instead of chars
    chunk_overlap=128,  # 25% overlap
    length_function=tiktoken_len,  # ä½¿ç”¨tokenè®¡æ•°
    separators=OPTIMIZED_SEPARATORS
)
```

### æ•ˆæœ
- åˆ†å—æ•°é‡ï¼š16ä¸ª
- å¹³å‡tokenæ•°ï¼š415.7
- æ£€ç´¢æˆåŠŸç‡ï¼š100%
- è¯­ä¹‰å®Œæ•´åº¦ï¼š1.88%ï¼ˆä»æœ‰93.8%è¯ä¸­æ–­ï¼‰

## ç¬¬äºŒæ­¥ä¼˜åŒ–ï¼šå¥å­è¾¹ç•Œæ£€æµ‹
**æ ¸å¿ƒæ€æƒ³**ï¼š"ä»'ä¸ç ´åè¯­ä¹‰'å‡çº§åˆ°'ä¸»åŠ¨ä¿æŒè¯­ä¹‰'"

### å®æ–½å†…å®¹
1. å®ç°åŸºäºå¥å­çš„åˆ†å—ç®—æ³•
2. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¯†åˆ«ä¸­è‹±æ–‡å¥å­è¾¹ç•Œ
3. åŸºäºå¥å­æ•°é‡è€Œéå­—ç¬¦æ•°çš„é‡å 
4. ä¿è¯æ¯ä¸ªåˆ†å—éƒ½ä»¥å®Œæ•´å¥å­ç»“å°¾

### ä»£ç å®ç°
```python
def split_text_by_sentence(text: str, chunk_size: int = 512, overlap_sentences: int = 3):
    # åˆ†å¥ï¼šä¸­æ–‡ï¼ˆã€‚ï¼ï¼Ÿï¼›ï¼‰å’Œè‹±æ–‡ï¼ˆ.!?ï¼‰
    sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿï¼›\.\?!])\s*', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    chunks = []
    current_chunk_sentences = []
    current_chunk_tokens = 0
    
    for sentence in sentences:
        sentence_tokens = tiktoken_len(sentence)
        
        if current_chunk_tokens + sentence_tokens > chunk_size and current_chunk_sentences:
            chunks.append(" ".join(current_chunk_sentences))
            
            # å¥å­çº§é‡å 
            start_index = max(0, len(current_chunk_sentences) - overlap_sentences)
            current_chunk_sentences = current_chunk_sentences[start_index:]
            current_chunk_tokens = tiktoken_len(" ".join(current_chunk_sentences))
        
        current_chunk_sentences.append(sentence)
        current_chunk_tokens += sentence_tokens
    
    return chunks
```

### æ•ˆæœå¯¹æ¯”

| æŒ‡æ ‡ | ç¬¬ä¸€æ­¥ä¼˜åŒ– | ç¬¬äºŒæ­¥ä¼˜åŒ– | æ”¹è¿› |
|------|-----------|-----------|------|
| åˆ†å—æ•°é‡ | 16 | 14 | -12.5% |
| å¹³å‡tokens | 415.7 | 468.1 | +12.6% |
| è¯­ä¹‰å®Œæ•´åº¦ | 1.88% | 92.86% | +4837% |
| å¥å­å®Œæ•´ç‡ | 6.2% | 92.9% | +1398% |
| æ£€ç´¢æˆåŠŸç‡ | 100% | 100% | 0% |

## å…³é”®æˆæœ

### ğŸ¯ ç¬¬ä¸€æ­¥ä¼˜åŒ–æˆæœ
1. **è§£å†³äº†ä¸­è‹±æ–‡ä¸å…¬å¹³é—®é¢˜**ï¼šä¸­æ–‡å¹³å‡1.25 tokens/å­—ç¬¦ï¼Œè‹±æ–‡0.18 tokens/å­—ç¬¦
2. **åˆ†å—æ›´å¤§æ›´å®Œæ•´**ï¼šä»106å­—ç¬¦æå‡åˆ°1784å­—ç¬¦
3. **æ£€ç´¢æˆåŠŸç‡è¾¾åˆ°100%**ï¼šä»0%æå‡åˆ°100%

### ğŸš€ ç¬¬äºŒæ­¥ä¼˜åŒ–æˆæœ
1. **è¯­ä¹‰å®Œæ•´åº¦è´¨çš„é£è·ƒ**ï¼šä»1.88%æå‡åˆ°92.86%
2. **å‡ ä¹æ¶ˆé™¤äº†è¯ä¸­æ–­**ï¼šä»93.8%é™ä½åˆ°7.1%
3. **æ›´ç¨³å®šçš„åˆ†å—è´¨é‡**ï¼šæ ‡å‡†å·®ä»111.8é™ä½åˆ°117.6ï¼ˆç›¸å¯¹äºæ›´å¤§çš„å¹³å‡å€¼ï¼‰
4. **ä¿æŒäº†æ£€ç´¢çš„é«˜æˆåŠŸç‡**ï¼š100%

## å®è·µå»ºè®®

1. **å¯¹äºå­¦æœ¯æ–‡æ¡£å’Œé•¿æ–‡æœ¬**ï¼šä¼˜å…ˆä½¿ç”¨å¥å­åˆ†å—ç­–ç•¥
2. **å¯¹äºçŸ­æ–‡æœ¬æˆ–å¯¹è¯**ï¼šå¯ä»¥è€ƒè™‘ä½¿ç”¨tokenåˆ†å—
3. **æ··åˆæ–‡æ¡£**ï¼šå»ºè®®ä½¿ç”¨å¥å­åˆ†å—ï¼Œå®ƒå¯¹ä¸­è‹±æ–‡éƒ½å‹å¥½
4. **æ€§èƒ½è€ƒè™‘**ï¼šå¥å­åˆ†å—ç•¥æ…¢äºtokenåˆ†å—ï¼Œä½†è´¨é‡æå‡æ˜æ˜¾

## ä¸‹ä¸€æ­¥å±•æœ›
ç­‰å¾…ç¬¬ä¸‰æ­¥ä¼˜åŒ–æ–¹æ¡ˆï¼Œå¯èƒ½çš„æ–¹å‘ï¼š
- è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†å—
- å±‚æ¬¡åŒ–åˆ†å—ï¼ˆæ®µè½â†’å¥å­â†’çŸ­è¯­ï¼‰
- åŠ¨æ€åˆ†å—å¤§å°ï¼ˆåŸºäºå†…å®¹å¤æ‚åº¦ï¼‰
- ä¸»é¢˜è¿è´¯æ€§æ£€æµ‹